[program started on Fri Jan 22 17:53:51 2016] 
[command line arguments] 
plot true 
preTrain false 
loss reinforce 
preTrainEpochs 50 
save testing 
momentum 0.7 
batchSize 10 
dataset lol 
seed 123 
learningRate 0.01 
epochs 10000 
weightDecay 0 
threads 1 
[----------------------] 
==> Loading scripts 
==> Loading data 
==> Preprocessing data 
==> Preprocessing normalization 
(1,.,.) = 
 Columns 1 to 9
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723

Columns 10 to 18
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.1567  0.0745  0.2673
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723  0.1902  1.0767  1.8090
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723  0.4985  2.0017  3.2736
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723  0.5371  2.1944  3.2736
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723  0.6141  2.3871  3.2736
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723  0.3443  1.5777  2.1559
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.0411  0.4214  0.6141
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.1182
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723  0.1516
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723  0.3829
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723  0.4214
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723  0.4214
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723  0.1516
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.1567
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723

Columns 19 to 27
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
  0.4214  0.4985  0.4985  0.4985  0.4600  0.4600  0.4985  0.4985  0.4600
  2.3486  2.6569  2.6569  2.6569  2.6569  2.6569  2.6955  2.6955  2.6569
  4.2372  4.6997  4.7382  4.7382  4.6997  4.6997  4.7768  4.7768  4.7382
  3.7746  3.9674  3.8903  3.8517  3.8132  3.9288  4.1215  4.3913  4.6226
  3.3121  3.2351  3.0423  2.9653  2.9267  3.1194  3.5434  4.0059  4.5455
  2.0788  1.9631  1.8475  1.7704  1.7704  2.1173  2.8882  3.6590  4.5070
  0.5756  0.5371  0.4985  0.4600  0.4600  1.0381  2.2329  3.3507  4.4684
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723  0.4985  2.1173  3.5048  4.6997
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723  0.7298  2.7340  4.2757  5.2778
 -0.2723 -0.2723 -0.2723 -0.2338 -0.1567  1.0381  3.4278  5.0080  5.8174
 -0.2723 -0.2723 -0.2723  0.0745  0.7683  2.2329  4.4299  5.7403  6.2028
 -0.2723 -0.2723 -0.2723  0.3829  1.7319  3.3892  5.4705  6.5112  6.5497
 -0.2723 -0.2723 -0.2723  0.5371  2.1944  3.9674  5.7789  6.7039  6.6268
 -0.2723 -0.2723 -0.2723  0.6912  2.5798  4.3528  5.9716  6.7424  6.6654
 -0.2723 -0.2723 -0.2723  0.8069  2.9653  4.7382  6.1258  6.7039  6.4726
 -0.2723 -0.2723 -0.2723  0.9225  3.3507  5.1236  6.2799  6.5883  6.0487
 -0.2723 -0.2338 -0.1182  1.2308  3.7746  5.5091  6.3956  6.4341  5.6247
 -0.2723  0.0745  0.8069  2.1944  4.3528  5.7403  6.3185  6.1258  5.1622
 -0.2723  0.3829  1.6933  3.1965  4.9695  5.9716  6.2028  5.8174  4.6997
 -0.2723  0.5756  2.3100  3.8517  5.2393  5.9330  5.9716  5.3164  4.0444
 -0.2723  0.7683  2.8882  4.4684  5.4705  5.8945  5.7018  4.8538  3.3892
  0.2287  1.4235  3.5048  4.8924  5.5476  5.7018  5.3549  4.3142  2.5413
  1.0381  2.3871  4.1601  5.2007  5.5476  5.4705  5.0080  3.6976  1.6163
  1.6933  3.0423  4.5070  5.2778  5.3164  5.0851  4.5840  3.1580  0.8839
  1.7704  2.9653  4.0059  4.5455  4.5840  4.3913  3.9674  2.7725  0.7298
  1.8475  2.8496  3.5048  3.8132  3.8132  3.6976  3.3507  2.3486  0.6141
  0.9610  1.5392  1.9246  2.1173  2.1173  2.0402  1.8475  1.2308  0.2287
  0.0360  0.1902  0.3058  0.3443  0.3443  0.3058  0.2673  0.1131 -0.1567
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723

Columns 28 to 36
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
  0.4600  0.4600  0.4600  0.4214  0.3443  0.1902  0.1131 -0.2723 -0.2723
  2.6184  2.6184  2.5798  2.4257  2.0788  1.5777  1.3079 -0.2723 -0.2723
  4.6997  4.6997  4.5840  4.3528  3.7746  2.8496  2.3871 -0.2723 -0.2723
  4.8153  4.8924  4.7382  4.2757  3.3507  1.9246  1.1923 -0.2723 -0.2723
  4.9309  5.0851  4.8538  4.1986  2.9267  0.9996  0.0360 -0.2723 -0.2723
  5.0080  5.1236  4.7382  3.8903  2.5027  0.6527 -0.2723 -0.2723 -0.2723
  5.0466  5.0851  4.5455  3.4663  2.1173  0.4985 -0.2723 -0.2723 -0.2723
  5.2393  5.0851  4.2757  2.8111  1.4621  0.3058 -0.2723 -0.2723 -0.2723
  5.5476  5.1236  3.8903  1.8475  0.5371 -0.0025 -0.2723 -0.2723 -0.2723
  5.8560  5.1622  3.5434  0.9996 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
  5.9716  5.1236  3.4278  0.9610 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
  6.0872  5.0466  3.3121  0.9225 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
  5.9716  4.6226  2.9267  0.7683 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
  5.8174  4.1601  2.4257  0.6141 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
  5.3164  3.3121  1.6548  0.3829 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
  4.5455  2.0788  0.5756 -0.0025 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
  3.8517  1.0767 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
  3.4663  0.9610 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
  3.0423  0.8454 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
  2.5027  0.6527 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
  1.9246  0.4600 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
  1.1923  0.2287 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
  0.3443 -0.0796 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723

Columns 37 to 45
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723

Columns 46 to 54
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723

Columns 55 to 60
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723 -0.2723
[torch.DoubleTensor of size 1x60x60]
 
==> define parameters of the model 
==> construct model 
==> define loss 
==> here is the loss function: 
nn.ParallelCriterion 
==> defining some tools 
==> configuring optimizer 
==> defining training procedure 
==> defining test procedure 
==> Training 
==> doing epoch on training data: 
==> online epoch # 0 [batchSize = 10] 
7 
-1.3232
-1.4743
-2.9998
-2.3852
-2.7496
-3.0377
-2.5258
-3.1621
-2.9392
-2.5798
[torch.DoubleTensor of size 10]
 
-0.082639286542902 X 0.75249742624737 
-0.8 X 0.8 
-0.8 X 0.29786164242364 
-0.54767076266554 X 0.74451852488647 
-0.8 X 0.8 

==> time to learn 1 sample = 7.5049567967653ms 
ConfusionMatrix:
[[      20      81       0       0      12       0       1       0       0       0]   17.544% 	[class: 1]
 [      26      92       0       0      10       0       0       0       1       0]   71.318% 	[class: 2]
 [       3      23       0       0       6       0       0       0       0       0]   0.000% 	[class: 3]
 [       8      42       0       0       3       0       0       0       0       0]   0.000% 	[class: 4]
 [       4      29       0       0       4       0       1       0       0       0]   10.526% 	[class: 5]
 [       2      17       0       0       3       0       0       0       0       0]   0.000% 	[class: 6]
 [       8      25       0       0       5       0       0       0       0       0]   0.000% 	[class: 7]
 [       5      19       0       0       1       0       1       0       1       0]   0.000% 	[class: 8]
 [       3      18       0       0       1       0       0       0       0       0]   0.000% 	[class: 9]
 [       6      26       0       0       4       0       0       0       1       0]]  0.000% 	[class: 0]
 + average row correct: 9.9388003349304% 
 + average rowUcol correct (VOC measure): 3.8486348092556% 
 + global correct: 22.65625% 
==> testing on test set: 
9 
-1.3595
-1.5095
-2.9880
-2.1696
-2.7663
-3.0502
-2.5570
-3.1914
-2.9724
-2.5575
[torch.DoubleTensor of size 10]
 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 

==> time to test 1 sample = 2.9503768140619ms 
ConfusionMatrix:
[[      45       0       0       0       0       0       0       0       0       0]   100.000% 	[class: 1]
 [      48       0       0       0       0       0       0       0       0       0]   0.000% 	[class: 2]
 [      15       0       0       0       0       0       0       0       0       0]   0.000% 	[class: 3]
 [      27       0       0       0       0       0       0       0       0       0]   0.000% 	[class: 4]
 [      19       0       0       0       0       0       0       0       0       0]   0.000% 	[class: 5]
 [       7       0       0       0       0       0       0       0       0       0]   0.000% 	[class: 6]
 [      16       0       0       0       0       0       0       0       0       0]   0.000% 	[class: 7]
 [      12       0       0       0       0       0       0       0       0       0]   0.000% 	[class: 8]
 [      15       0       0       0       0       0       0       0       0       0]   0.000% 	[class: 9]
 [      16       0       0       0       0       0       0       0       0       0]]  0.000% 	[class: 0]
 + average row correct: 10% 
 + average rowUcol correct (VOC measure): 2.045454531908% 
 + global correct: 20.454545454545% 
==> doing epoch on training data: 
==> online epoch # 1 [batchSize = 10] 
7 
-1.5171
-1.4876
-2.7323
-2.3007
-2.5077
-3.0369
-2.5472
-2.8597
-3.0136
-2.5854
[torch.DoubleTensor of size 10]
 
-0.74360846336032 X -0.47519682174113 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 
-0.051842663434266 X 0.8 

==> time to learn 1 sample = 7.427972741425ms 
ConfusionMatrix:
[[      33      81       0       0       0       0       0       0       0       0]   28.947% 	[class: 1]
 [      34      95       0       0       0       0       0       0       0       0]   73.643% 	[class: 2]
 [      11      21       0       0       0       0       0       0       0       0]   0.000% 	[class: 3]
 [      18      35       0       0       0       0       0       0       0       0]   0.000% 	[class: 4]
 [      13      25       0       0       0       0       0       0       0       0]   0.000% 	[class: 5]
 [       9      13       0       0       0       0       0       0       0       0]   0.000% 	[class: 6]
 [       8      30       0       0       0       0       0       0       0       0]   0.000% 	[class: 7]
 [       5      22       0       0       0       0       0       0       0       0]   0.000% 	[class: 8]
 [       8      14       0       0       0       0       0       0       0       0]   0.000% 	[class: 9]
 [       8      29       0       0       0       0       0       0       0       0]]  0.000% 	[class: 0]
 + average row correct: 10.259077847004% 
 + average rowUcol correct (VOC measure): 3.8283208012581% 
 + global correct: 25% 
==> testing on test set: 
9 
-1.5084
-1.3829
-2.7902
-2.3520
-2.5713
-3.0804
-2.6141
-2.8561
-3.0997
-2.6157
[torch.DoubleTensor of size 10]
 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 

==> time to test 1 sample = 3.4138365225358ms 
ConfusionMatrix:
[[       0      45       0       0       0       0       0       0       0       0]   0.000% 	[class: 1]
 [       0      48       0       0       0       0       0       0       0       0]   100.000% 	[class: 2]
 [       0      15       0       0       0       0       0       0       0       0]   0.000% 	[class: 3]
 [       0      27       0       0       0       0       0       0       0       0]   0.000% 	[class: 4]
 [       0      19       0       0       0       0       0       0       0       0]   0.000% 	[class: 5]
 [       0       7       0       0       0       0       0       0       0       0]   0.000% 	[class: 6]
 [       0      16       0       0       0       0       0       0       0       0]   0.000% 	[class: 7]
 [       0      12       0       0       0       0       0       0       0       0]   0.000% 	[class: 8]
 [       0      15       0       0       0       0       0       0       0       0]   0.000% 	[class: 9]
 [       0      16       0       0       0       0       0       0       0       0]]  0.000% 	[class: 0]
 + average row correct: 10% 
 + average rowUcol correct (VOC measure): 2.1818181872368% 
 + global correct: 21.818181818182% 
==> doing epoch on training data: 
==> online epoch # 2 [batchSize = 10] 
7 
-1.6018
-1.4249
-2.6982
-2.2302
-2.5348
-3.1370
-2.5023
-2.8611
-3.1028
-2.5720
[torch.DoubleTensor of size 10]
 
0.56411709245756 X 0.37724967123472 
-0.8 X 0.8 
-0.8 X 0.55209965918898 
-0.64023115238249 X 0.8 
-0.67369461136384 X 0.8 

==> time to learn 1 sample = 7.7784103341401ms 
ConfusionMatrix:
[[      19      95       0       0       0       0       0       0       0       0]   16.667% 	[class: 1]
 [      22     107       0       0       0       0       0       0       0       0]   82.946% 	[class: 2]
 [       8      24       0       0       0       0       0       0       0       0]   0.000% 	[class: 3]
 [      10      43       0       0       0       0       0       0       0       0]   0.000% 	[class: 4]
 [       7      31       0       0       0       0       0       0       0       0]   0.000% 	[class: 5]
 [       1      21       0       0       0       0       0       0       0       0]   0.000% 	[class: 6]
 [       5      33       0       0       0       0       0       0       0       0]   0.000% 	[class: 7]
 [       6      21       0       0       0       0       0       0       0       0]   0.000% 	[class: 8]
 [       2      20       0       0       0       0       0       0       0       0]   0.000% 	[class: 9]
 [      10      27       0       0       0       0       0       0       0       0]]  0.000% 	[class: 0]
 + average row correct: 9.9612401425838% 
 + average rowUcol correct (VOC measure): 3.4369369596243% 
 + global correct: 24.609375% 
==> testing on test set: 
9 
-1.6225
-1.4970
-2.6529
-2.1627
-2.5141
-3.1103
-2.5233
-2.8448
-3.1038
-2.4698
[torch.DoubleTensor of size 10]
 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 

==> time to test 1 sample = 3.0064366080544ms 
ConfusionMatrix:
[[       1      44       0       0       0       0       0       0       0       0]   2.222% 	[class: 1]
 [       0      48       0       0       0       0       0       0       0       0]   100.000% 	[class: 2]
 [       0      15       0       0       0       0       0       0       0       0]   0.000% 	[class: 3]
 [       0      27       0       0       0       0       0       0       0       0]   0.000% 	[class: 4]
 [       0      19       0       0       0       0       0       0       0       0]   0.000% 	[class: 5]
 [       0       7       0       0       0       0       0       0       0       0]   0.000% 	[class: 6]
 [       0      16       0       0       0       0       0       0       0       0]   0.000% 	[class: 7]
 [       0      12       0       0       0       0       0       0       0       0]   0.000% 	[class: 8]
 [       0      15       0       0       0       0       0       0       0       0]   0.000% 	[class: 9]
 [       0      16       0       0       0       0       0       0       0       0]]  0.000% 	[class: 0]
 + average row correct: 10.222222227603% 
 + average rowUcol correct (VOC measure): 2.414003033191% 
 + global correct: 22.272727272727% 
==> doing epoch on training data: 
==> online epoch # 3 [batchSize = 10] 
7 
-1.3841
-1.4581
-2.8841
-2.3208
-2.7252
-3.1045
-2.6177
-2.8651
-3.1104
-2.5541
[torch.DoubleTensor of size 10]
 
-0.3211468458788 X -0.089935320388094 
-0.8 X 0.8 
-0.26409881753876 X 0.72729093650429 
-0.53589338857865 X 0.8 
-0.67213578063728 X 0.32417260129803 

==> time to learn 1 sample = 7.6427073217928ms 
ConfusionMatrix:
[[      26      88       0       0       0       0       0       0       0       0]   22.807% 	[class: 1]
 [      28     101       0       0       0       0       0       0       0       0]   78.295% 	[class: 2]
 [       5      27       0       0       0       0       0       0       0       0]   0.000% 	[class: 3]
 [      15      38       0       0       0       0       0       0       0       0]   0.000% 	[class: 4]
 [      12      26       0       0       0       0       0       0       0       0]   0.000% 	[class: 5]
 [       6      16       0       0       0       0       0       0       0       0]   0.000% 	[class: 6]
 [      11      27       0       0       0       0       0       0       0       0]   0.000% 	[class: 7]
 [       7      20       0       0       0       0       0       0       0       0]   0.000% 	[class: 8]
 [       4      18       0       0       0       0       0       0       0       0]   0.000% 	[class: 9]
 [       9      28       0       0       0       0       0       0       0       0]]  0.000% 	[class: 0]
 + average row correct: 10.110159218311% 
 + average rowUcol correct (VOC measure): 3.6542897671461% 
 + global correct: 24.8046875% 
==> testing on test set: 
9 
-1.4500
-1.5405
-2.6834
-2.3186
-2.5466
-3.0982
-2.5986
-2.8434
-3.1090
-2.4809
[torch.DoubleTensor of size 10]
 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 

==> time to test 1 sample = 3.1480138952082ms 
ConfusionMatrix:
[[      45       0       0       0       0       0       0       0       0       0]   100.000% 	[class: 1]
 [      45       3       0       0       0       0       0       0       0       0]   6.250% 	[class: 2]
 [      15       0       0       0       0       0       0       0       0       0]   0.000% 	[class: 3]
 [      26       1       0       0       0       0       0       0       0       0]   0.000% 	[class: 4]
 [      19       0       0       0       0       0       0       0       0       0]   0.000% 	[class: 5]
 [       7       0       0       0       0       0       0       0       0       0]   0.000% 	[class: 6]
 [      15       1       0       0       0       0       0       0       0       0]   0.000% 	[class: 7]
 [      12       0       0       0       0       0       0       0       0       0]   0.000% 	[class: 8]
 [      15       0       0       0       0       0       0       0       0       0]   0.000% 	[class: 9]
 [      16       0       0       0       0       0       0       0       0       0]]  0.000% 	[class: 0]
 + average row correct: 10.625% 
 + average rowUcol correct (VOC measure): 2.6930231973529% 
 + global correct: 21.818181818182% 
==> doing epoch on training data: 
==> online epoch # 4 [batchSize = 10] 
7 
-1.4941
-1.4835
-2.8411
-2.2109
-2.6078
-3.1039
-2.5500
-2.7897
-3.1236
-2.5427
[torch.DoubleTensor of size 10]
 
-0.8 X 0.8 
-0.7257971797611 X 0.58597219596952 
-0.62674011784868 X -0.40855050758126 
-0.056751483938641 X 0.8 
-0.8 X 0.8 

==> time to learn 1 sample = 7.4513182044029ms 
ConfusionMatrix:
[[      17      97       0       0       0       0       0       0       0       0]   14.912% 	[class: 1]
 [      32      97       0       0       0       0       0       0       0       0]   75.194% 	[class: 2]
 [       8      24       0       0       0       0       0       0       0       0]   0.000% 	[class: 3]
 [      16      37       0       0       0       0       0       0       0       0]   0.000% 	[class: 4]
 [       7      31       0       0       0       0       0       0       0       0]   0.000% 	[class: 5]
 [       5      17       0       0       0       0       0       0       0       0]   0.000% 	[class: 6]
 [       6      32       0       0       0       0       0       0       0       0]   0.000% 	[class: 7]
 [       4      23       0       0       0       0       0       0       0       0]   0.000% 	[class: 8]
 [       4      18       0       0       0       0       0       0       0       0]   0.000% 	[class: 9]
 [       6      31       0       0       0       0       0       0       0       0]]  0.000% 	[class: 0]
 + average row correct: 9.0106078982353% 
 + average rowUcol correct (VOC measure): 3.0511512607336% 
 + global correct: 22.265625% 
==> testing on test set: 
9 
-1.5089
-1.3936
-2.8265
-2.2479
-2.6231
-3.1315
-2.6334
-2.8466
-3.1930
-2.5426
[torch.DoubleTensor of size 10]
 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 

==> time to test 1 sample = 3.2021674242887ms 
ConfusionMatrix:
[[       0      45       0       0       0       0       0       0       0       0]   0.000% 	[class: 1]
 [       0      48       0       0       0       0       0       0       0       0]   100.000% 	[class: 2]
 [       0      15       0       0       0       0       0       0       0       0]   0.000% 	[class: 3]
 [       0      27       0       0       0       0       0       0       0       0]   0.000% 	[class: 4]
 [       0      19       0       0       0       0       0       0       0       0]   0.000% 	[class: 5]
 [       0       7       0       0       0       0       0       0       0       0]   0.000% 	[class: 6]
 [       0      16       0       0       0       0       0       0       0       0]   0.000% 	[class: 7]
 [       0      12       0       0       0       0       0       0       0       0]   0.000% 	[class: 8]
 [       0      15       0       0       0       0       0       0       0       0]   0.000% 	[class: 9]
 [       0      16       0       0       0       0       0       0       0       0]]  0.000% 	[class: 0]
 + average row correct: 10% 
 + average rowUcol correct (VOC measure): 2.1818181872368% 
 + global correct: 21.818181818182% 
==> doing epoch on training data: 
==> online epoch # 5 [batchSize = 10] 
7 
-1.3493
-1.3689
-2.8451
-2.2912
-2.7148
-3.1664
-2.7503
-2.9683
-3.2457
-2.7442
[torch.DoubleTensor of size 10]
 
-0.8 X 0.8 
-0.33906695998806 X 0.8 
-0.8 X 0.67887387685977 
-0.27589783478503 X 0.8 
0.066208578161944 X 0.8 

==> time to learn 1 sample = 7.5201173312962ms 
ConfusionMatrix:
[[      27      87       0       0       0       0       0       0       0       0]   23.684% 	[class: 1]
 [      25     104       0       0       0       0       0       0       0       0]   80.620% 	[class: 2]
 [       8      24       0       0       0       0       0       0       0       0]   0.000% 	[class: 3]
 [       9      44       0       0       0       0       0       0       0       0]   0.000% 	[class: 4]
 [       6      32       0       0       0       0       0       0       0       0]   0.000% 	[class: 5]
 [       5      17       0       0       0       0       0       0       0       0]   0.000% 	[class: 6]
 [       2      36       0       0       0       0       0       0       0       0]   0.000% 	[class: 7]
 [       5      22       0       0       0       0       0       0       0       0]   0.000% 	[class: 8]
 [       2      20       0       0       0       0       0       0       0       0]   0.000% 	[class: 9]
 [       5      32       0       0       0       0       0       0       0       0]]  0.000% 	[class: 0]
 + average row correct: 10.430436879396% 
 + average rowUcol correct (VOC measure): 3.8393425941467% 
 + global correct: 25.5859375% 
==> testing on test set: 
9 
-1.2868
-1.4535
-2.8045
-2.3086
-2.6946
-3.1640
-2.7941
-2.9495
-3.2088
-2.7121
[torch.DoubleTensor of size 10]
 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 

==> time to test 1 sample = 2.8794407844543ms 
ConfusionMatrix:
[[      45       0       0       0       0       0       0       0       0       0]   100.000% 	[class: 1]
 [      47       1       0       0       0       0       0       0       0       0]   2.083% 	[class: 2]
 [      15       0       0       0       0       0       0       0       0       0]   0.000% 	[class: 3]
 [      26       1       0       0       0       0       0       0       0       0]   0.000% 	[class: 4]
 [      19       0       0       0       0       0       0       0       0       0]   0.000% 	[class: 5]
 [       7       0       0       0       0       0       0       0       0       0]   0.000% 	[class: 6]
 [      16       0       0       0       0       0       0       0       0       0]   0.000% 	[class: 7]
 [      12       0       0       0       0       0       0       0       0       0]   0.000% 	[class: 8]
 [      15       0       0       0       0       0       0       0       0       0]   0.000% 	[class: 9]
 [      16       0       0       0       0       0       0       0       0       0]]  0.000% 	[class: 0]
 + average row correct: 10.208333339542% 
 + average rowUcol correct (VOC measure): 2.2683017887175% 
 + global correct: 20.909090909091% 
==> doing epoch on training data: 
==> online epoch # 6 [batchSize = 10] 
7 
-1.4768
-1.2746
-2.8013
-2.3633
-2.6965
-3.1752
-2.7453
-2.9762
-3.1753
-2.6451
[torch.DoubleTensor of size 10]
 
-0.67482427062154 X 0.36735428372158 
-0.8 X -0.18859658626032 
-0.8 X 0.46270363405718 
-0.8 X 0.8 
-0.8 X 0.64608590729783 

==> time to learn 1 sample = 7.5073926709592ms 
ConfusionMatrix:
[[      52      62       0       0       0       0       0       0       0       0]   45.614% 	[class: 1]
 [      50      79       0       0       0       0       0       0       0       0]   61.240% 	[class: 2]
 [      16      16       0       0       0       0       0       0       0       0]   0.000% 	[class: 3]
 [      20      33       0       0       0       0       0       0       0       0]   0.000% 	[class: 4]
 [      20      18       0       0       0       0       0       0       0       0]   0.000% 	[class: 5]
 [      11      11       0       0       0       0       0       0       0       0]   0.000% 	[class: 6]
 [      20      18       0       0       0       0       0       0       0       0]   0.000% 	[class: 7]
 [      13      14       0       0       0       0       0       0       0       0]   0.000% 	[class: 8]
 [      13       9       0       0       0       0       0       0       0       0]   0.000% 	[class: 9]
 [      11      26       0       0       0       0       0       0       0       0]]  0.000% 	[class: 0]
 + average row correct: 10.685434341431% 
 + average rowUcol correct (VOC measure): 4.1567459702492% 
 + global correct: 25.5859375% 
==> testing on test set: 
9 
-1.4925
-1.3038
-2.7402
-2.3676
-2.6665
-3.1534
-2.7683
-2.9666
-3.1964
-2.5505
[torch.DoubleTensor of size 10]
 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 

==> time to test 1 sample = 2.8326587243514ms 
ConfusionMatrix:
[[       0      45       0       0       0       0       0       0       0       0]   0.000% 	[class: 1]
 [       0      48       0       0       0       0       0       0       0       0]   100.000% 	[class: 2]
 [       0      15       0       0       0       0       0       0       0       0]   0.000% 	[class: 3]
 [       0      27       0       0       0       0       0       0       0       0]   0.000% 	[class: 4]
 [       0      19       0       0       0       0       0       0       0       0]   0.000% 	[class: 5]
 [       0       7       0       0       0       0       0       0       0       0]   0.000% 	[class: 6]
 [       0      16       0       0       0       0       0       0       0       0]   0.000% 	[class: 7]
 [       0      12       0       0       0       0       0       0       0       0]   0.000% 	[class: 8]
 [       0      15       0       0       0       0       0       0       0       0]   0.000% 	[class: 9]
 [       0      16       0       0       0       0       0       0       0       0]]  0.000% 	[class: 0]
 + average row correct: 10% 
 + average rowUcol correct (VOC measure): 2.1818181872368% 
 + global correct: 21.818181818182% 
==> doing epoch on training data: 
==> online epoch # 7 [batchSize = 10] 
7 
-1.5528
-1.4919
-2.6864
-2.3110
-2.5215
-3.0328
-2.5650
-2.7934
-3.0379
-2.5069
[torch.DoubleTensor of size 10]
 
-0.8 X 0.8 
-0.8 X 0.40436989916123 
-0.12256462771491 X 0.21088248364819 
-0.8 X 0.8 
-0.67637023939732 X 0.8 

==> time to learn 1 sample = 7.7203027904034ms 
ConfusionMatrix:
[[      14     100       0       0       0       0       0       0       0       0]   12.281% 	[class: 1]
 [      22     107       0       0       0       0       0       0       0       0]   82.946% 	[class: 2]
 [      10      22       0       0       0       0       0       0       0       0]   0.000% 	[class: 3]
 [      13      40       0       0       0       0       0       0       0       0]   0.000% 	[class: 4]
 [       8      30       0       0       0       0       0       0       0       0]   0.000% 	[class: 5]
 [       3      19       0       0       0       0       0       0       0       0]   0.000% 	[class: 6]
 [       5      33       0       0       0       0       0       0       0       0]   0.000% 	[class: 7]
 [       4      23       0       0       0       0       0       0       0       0]   0.000% 	[class: 8]
 [       3      19       0       0       0       0       0       0       0       0]   0.000% 	[class: 9]
 [       3      34       0       0       0       0       0       0       0       0]]  0.000% 	[class: 0]
 + average row correct: 9.5226436108351% 
 + average rowUcol correct (VOC measure): 3.1398303061724% 
 + global correct: 23.6328125% 
==> testing on test set: 
9 
-1.5072
-1.5097
-2.6477
-2.3322
-2.5181
-3.0468
-2.6191
-2.7958
-3.0923
-2.4994
[torch.DoubleTensor of size 10]
 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 

==> time to test 1 sample = 3.3719225363298ms 
ConfusionMatrix:
[[      12      33       0       0       0       0       0       0       0       0]   26.667% 	[class: 1]
 [       2      46       0       0       0       0       0       0       0       0]   95.833% 	[class: 2]
 [       3      12       0       0       0       0       0       0       0       0]   0.000% 	[class: 3]
 [       3      24       0       0       0       0       0       0       0       0]   0.000% 	[class: 4]
 [       2      17       0       0       0       0       0       0       0       0]   0.000% 	[class: 5]
 [       3       4       0       0       0       0       0       0       0       0]   0.000% 	[class: 6]
 [       3      13       0       0       0       0       0       0       0       0]   0.000% 	[class: 7]
 [       4       8       0       0       0       0       0       0       0       0]   0.000% 	[class: 8]
 [       2      13       0       0       0       0       0       0       0       0]   0.000% 	[class: 9]
 [       4      12       0       0       0       0       0       0       0       0]]  0.000% 	[class: 0]
 + average row correct: 12.249999940395% 
 + average rowUcol correct (VOC measure): 4.1901408135891% 
 + global correct: 26.363636363636% 
==> doing epoch on training data: 
==> online epoch # 8 [batchSize = 10] 
7 
-1.5931
-1.3413
-2.7539
-2.3527
-2.5736
-3.0369
-2.5594
-2.9108
-3.0114
-2.6431
[torch.DoubleTensor of size 10]
 
-0.18583813420498 X 0.25101879148788 
-0.45276339172864 X 0.63311826752019 
-0.8 X 0.8 
-0.42876294856967 X 0.8 
-0.71207122356072 X -0.05719693613667 

==> time to learn 1 sample = 7.3162443004549ms 
ConfusionMatrix:
[[      31      83       0       0       0       0       0       0       0       0]   27.193% 	[class: 1]
 [      29     100       0       0       0       0       0       0       0       0]   77.519% 	[class: 2]
 [       8      24       0       0       0       0       0       0       0       0]   0.000% 	[class: 3]
 [      11      42       0       0       0       0       0       0       0       0]   0.000% 	[class: 4]
 [      13      25       0       0       0       0       0       0       0       0]   0.000% 	[class: 5]
 [       5      17       0       0       0       0       0       0       0       0]   0.000% 	[class: 6]
 [       7      31       0       0       0       0       0       0       0       0]   0.000% 	[class: 7]
 [       9      18       0       0       0       0       0       0       0       0]   0.000% 	[class: 8]
 [       5      17       0       0       0       0       0       0       0       0]   0.000% 	[class: 9]
 [       6      31       0       0       0       0       0       0       0       0]]  0.000% 	[class: 0]
 + average row correct: 10.471236407757% 
 + average rowUcol correct (VOC measure): 3.8956661522388% 
 + global correct: 25.5859375% 
==> testing on test set: 
9 
-1.5413
-1.4676
-2.6586
-2.3051
-2.5237
-3.0523
-2.5714
-2.8491
-3.0879
-2.5476
[torch.DoubleTensor of size 10]
 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 

==> time to test 1 sample = 2.2645961154591ms 
ConfusionMatrix:
[[       2      43       0       0       0       0       0       0       0       0]   4.444% 	[class: 1]
 [       0      48       0       0       0       0       0       0       0       0]   100.000% 	[class: 2]
 [       0      15       0       0       0       0       0       0       0       0]   0.000% 	[class: 3]
 [       1      26       0       0       0       0       0       0       0       0]   0.000% 	[class: 4]
 [       0      19       0       0       0       0       0       0       0       0]   0.000% 	[class: 5]
 [       1       6       0       0       0       0       0       0       0       0]   0.000% 	[class: 6]
 [       1      15       0       0       0       0       0       0       0       0]   0.000% 	[class: 7]
 [       1      11       0       0       0       0       0       0       0       0]   0.000% 	[class: 8]
 [       0      15       0       0       0       0       0       0       0       0]   0.000% 	[class: 9]
 [       0      16       0       0       0       0       0       0       0       0]]  0.000% 	[class: 0]
 + average row correct: 10.444444455206% 
 + average rowUcol correct (VOC measure): 2.6511538401246% 
 + global correct: 22.727272727273% 
==> doing epoch on training data: 
==> online epoch # 9 [batchSize = 10] 
7 
-1.6284
-1.4453
-2.6285
-2.2255
-2.5269
-3.0126
-2.5554
-2.8823
-3.0362
-2.5626
[torch.DoubleTensor of size 10]
 
0.29088894737286 X 0.62812939196175 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 
-0.29445206529555 X 0.8 

==> time to learn 1 sample = 7.295424118638ms 
ConfusionMatrix:
[[      14     100       0       0       0       0       0       0       0       0]   12.281% 	[class: 1]
 [       8     121       0       0       0       0       0       0       0       0]   93.798% 	[class: 2]
 [       1      31       0       0       0       0       0       0       0       0]   0.000% 	[class: 3]
 [       3      50       0       0       0       0       0       0       0       0]   0.000% 	[class: 4]
 [       2      36       0       0       0       0       0       0       0       0]   0.000% 	[class: 5]
 [       0      22       0       0       0       0       0       0       0       0]   0.000% 	[class: 6]
 [       1      37       0       0       0       0       0       0       0       0]   0.000% 	[class: 7]
 [       3      24       0       0       0       0       0       0       0       0]   0.000% 	[class: 8]
 [       2      20       0       0       0       0       0       0       0       0]   0.000% 	[class: 9]
 [       3      34       0       0       0       0       0       0       0       0]]  0.000% 	[class: 0]
 + average row correct: 10.607914850116% 
 + average rowUcol correct (VOC measure): 3.5270738601685% 
 + global correct: 26.3671875% 
==> testing on test set: 
9 
-1.5833
-1.5109
-2.5780
-2.2509
-2.5014
-3.0054
-2.5980
-2.7935
-3.0581
-2.5424
[torch.DoubleTensor of size 10]
 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 
-0.8 X 0.8 

==> time to test 1 sample = 2.2667949849909ms 
ConfusionMatrix:
[[       2      43       0       0       0       0       0       0       0       0]   4.444% 	[class: 1]
 [       0      48       0       0       0       0       0       0       0       0]   100.000% 	[class: 2]
 [       0      15       0       0       0       0       0       0       0       0]   0.000% 	[class: 3]
 [       1      26       0       0       0       0       0       0       0       0]   0.000% 	[class: 4]
 [       0      19       0       0       0       0       0       0       0       0]   0.000% 	[class: 5]
 [       2       5       0       0       0       0       0       0       0       0]   0.000% 	[class: 6]
 [       1      15       0       0       0       0       0       0       0       0]   0.000% 	[class: 7]
 [       1      11       0       0       0       0       0       0       0       0]   0.000% 	[class: 8]
 [       0      15       0       0       0       0       0       0       0       0]   0.000% 	[class: 9]
 [       0      16       0       0       0       0       0       0       0       0]]  0.000% 	[class: 0]
 + average row correct: 10.444444455206% 
 + average rowUcol correct (VOC measure): 2.6535210758448% 
 + global correct: 22.727272727273% 
==> doing epoch on training data: 
==> online epoch # 10 [batchSize = 10] 
7 
-1.7325
-1.5232
-2.7786
-2.2303
-2.6032
-2.8305
-2.4533
-2.7372
-2.7423
-2.4382
[torch.DoubleTensor of size 10]
 
0.49488661129427 X 0.8 
-0.33560317453641 X 0.34258242090656 
-0.8 X 0.8 
-0.76772431391367 X 0.48270131971532 
-0.8 X 0.26079696647018 

==> time to learn 1 sample = 7.2321640327573ms 
ConfusionMatrix:
[[      18      96       0       0       0       0       0       0       0       0]   15.789% 	[class: 1]
 [      33      96       0       0       0       0       0       0       0       0]   74.419% 	[class: 2]
 [       7      25       0       0       0       0       0       0       0       0]   0.000% 	[class: 3]
 [      17      36       0       0       0       0       0       0       0       0]   0.000% 	[class: 4]
 [       9      29       0       0       0       0       0       0       0       0]   0.000% 	[class: 5]
 [       4      18       0       0       0       0       0       0       0       0]   0.000% 	[class: 6]
 [       4      34       0       0       0       0       0       0       0       0]   0.000% 	[class: 7]
 [      10      17       0       0       0       0       0       0       0       0]   0.000% 	[class: 8]
 [       3      19       0       0       0       0       0       0       0       0]   0.000% 	[class: 9]
 [      12      25       0       0       0       0       0       0       0       0]]  0.000% 	[class: 0]
 + average row correct: 9.0208077430725% 
 + average rowUcol correct (VOC measure): 3.0880609899759% 
 + global correct: 22.265625% 
==> testing on test set: 
9 
-1.6514
-1.5873
-2.4936
-2.2821
-2.4844
-2.8907
-2.5229
-2.7102
-2.9201
-2.5322
[torch.DoubleTensor of size 10]
 
-0.8 X 0.76248241579067 
-0.8 X 0.76248241579067 
-0.8 X 0.76248241579067 
-0.8 X 0.76248241579067 
-0.8 X 0.76248241579067 

==> time to test 1 sample = 2.1878914399581ms 
ConfusionMatrix:
[[       3      42       0       0       0       0       0       0       0       0]   6.667% 	[class: 1]
 [       0      48       0       0       0       0       0       0       0       0]   100.000% 	[class: 2]
 [       1      14       0       0       0       0       0       0       0       0]   0.000% 	[class: 3]
 [       2      25       0       0       0       0       0       0       0       0]   0.000% 	[class: 4]
 [       1      18       0       0       0       0       0       0       0       0]   0.000% 	[class: 5]
 [       2       5       0       0       0       0       0       0       0       0]   0.000% 	[class: 6]
 [       1      15       0       0       0       0       0       0       0       0]   0.000% 	[class: 7]
 [       2      10       0       0       0       0       0       0       0       0]   0.000% 	[class: 8]
 [       0      15       0       0       0       0       0       0       0       0]   0.000% 	[class: 9]
 [       0      16       0       0       0       0       0       0       0       0]]  0.000% 	[class: 0]
 + average row correct: 10.666666701436% 
 + average rowUcol correct (VOC measure): 2.8632478788495% 
 + global correct: 23.181818181818% 
==> doing epoch on training data: 
==> online epoch # 11 [batchSize = 10] 
7 
-1.5265
-1.3672
-2.7793
-2.3333
-2.6404
-3.0673
-2.5143
-2.8876
-3.0791
-2.6833
[torch.DoubleTensor of size 10]
 
0.3892232889523 X 0.45249927740369 
-0.8 X 0.64445994286963 
-0.8 X 0.8 
-0.2797827692807 X 0.56183531980804 
-0.8 X -0.45435233425619 

==> time to learn 1 sample = 7.2162463329732ms 
ConfusionMatrix:
[[       6     108       0       0       0       0       0       0       0       0]   5.263% 	[class: 1]
 [      12     117       0       0       0       0       0       0       0       0]   90.698% 	[class: 2]
 [       6      26       0       0       0       0       0       0       0       0]   0.000% 	[class: 3]
 [       7      46       0       0       0       0       0       0       0       0]   0.000% 	[class: 4]
 [       3      35       0       0       0       0       0       0       0       0]   0.000% 	[class: 5]
 [       4      18       0       0       0       0       0       0       0       0]   0.000% 	[class: 6]
 [       4      34       0       0       0       0       0       0       0       0]   0.000% 	[class: 7]
 [       2      25       0       0       0       0       0       0       0       0]   0.000% 	[class: 8]
 [       3      19       0       0       0       0       0       0       0       0]   0.000% 	[class: 9]
 [       6      31       0       0       0       0       0       0       0       0]]  0.000% 	[class: 0]
 + average row correct: 9.5960833877325% 
 + average rowUcol correct (VOC measure): 2.8567472845316% 
 + global correct: 24.0234375% 
==> testing on test set: 
9 
-1.5957
-1.3894
-2.7212
-2.3231
-2.6343
-2.9665
-2.5167
-2.7880
-3.0219
-2.6590
[torch.DoubleTensor of size 10]
 
-0.8 X 0.29684784588713 
-0.8 X 0.29684784588713 
-0.8 X 0.29684784588713 
-0.8 X 0.29684784588713 
-0.8 X 0.29684784588713 

==> time to test 1 sample = 2.2749955003912ms 
ConfusionMatrix:
[[       1      44       0       0       0       0       0       0       0       0]   2.222% 	[class: 1]
 [       2      46       0       0       0       0       0       0       0       0]   95.833% 	[class: 2]
 [       0      15       0       0       0       0       0       0       0       0]   0.000% 	[class: 3]
 [       0      27       0       0       0       0       0       0       0       0]   0.000% 	[class: 4]
 [       0      19       0       0       0       0       0       0       0       0]   0.000% 	[class: 5]
 [       0       7       0       0       0       0       0       0       0       0]   0.000% 	[class: 6]
 [       0      16       0       0       0       0       0       0       0       0]   0.000% 	[class: 7]
 [       0      12       0       0       0       0       0       0       0       0]   0.000% 	[class: 8]
 [       0      15       0       0       0       0       0       0       0       0]   0.000% 	[class: 9]
 [       1      15       0       0       0       0       0       0       0       0]]  0.000% 	[class: 0]
 + average row correct: 9.8055553622544% 
 + average rowUcol correct (VOC measure): 2.3184250853956% 
 + global correct: 21.363636363636% 
==> doing epoch on training data: 
==> online epoch # 12 [batchSize = 10] 
7 
-1.4477
-1.5174
-2.7672
-2.3265
-2.5956
-3.0273
-2.5533
-2.7274
-3.0723
-2.6234
[torch.DoubleTensor of size 10]
 
-0.13360261093725 X 0.35032379965952 
-0.66940202423266 X -0.3916341763564 
-0.72287343974828 X -0.0070495956077848 
-0.8 X 0.36796506559726 
-0.53436668144092 X 0.13228486388944 

==> time to learn 1 sample = 7.2162030264735ms 
ConfusionMatrix:
[[      13     101       0       0       0       0       0       0       0       0]   11.404% 	[class: 1]
 [       6     123       0       0       0       0       0       0       0       0]   95.349% 	[class: 2]
 [       1      31       0       0       0       0       0       0       0       0]   0.000% 	[class: 3]
 [       2      51       0       0       0       0       0       0       0       0]   0.000% 	[class: 4]
 [       2      36       0       0       0       0       0       0       0       0]   0.000% 	[class: 5]
 [       4      18       0       0       0       0       0       0       0       0]   0.000% 	[class: 6]
 [       5      33       0       0       0       0       0       0       0       0]   0.000% 	[class: 7]
 [       3      24       0       0       0       0       0       0       0       0]   0.000% 	[class: 8]
 [       3      19       0       0       0       0       0       0       0       0]   0.000% 	[class: 9]
 [       4      33       0       0       0       0       0       0       0       0]]  0.000% 	[class: 0]
 + average row correct: 10.675234347582% 
 + average rowUcol correct (VOC measure): 3.4922514855862% 
 + global correct: 26.5625% 
==> testing on test set: 
9 
-1.4327
-1.4972
-2.8410
-2.3331
-2.5935
-3.0376
-2.5729
-2.7560
-3.0669
-2.6162
[torch.DoubleTensor of size 10]
 
-0.8 X -0.015321990866727 
-0.8 X -0.015321990866727 
-0.8 X -0.015321990866727 
-0.8 X -0.015321990866727 
-0.8 X -0.015321990866727 

==> time to test 1 sample = 2.2168950601058ms 
ConfusionMatrix:
[[      40       5       0       0       0       0       0       0       0       0]   88.889% 	[class: 1]
 [      43       5       0       0       0       0       0       0       0       0]   10.417% 	[class: 2]
 [      13       2       0       0       0       0       0       0       0       0]   0.000% 	[class: 3]
 [      25       2       0       0       0       0       0       0       0       0]   0.000% 	[class: 4]
 [      18       1       0       0       0       0       0       0       0       0]   0.000% 	[class: 5]
 [       6       1       0       0       0       0       0       0       0       0]   0.000% 	[class: 6]
 [      15       1       0       0       0       0       0       0       0       0]   0.000% 	[class: 7]
 [      11       1       0       0       0       0       0       0       0       0]   0.000% 	[class: 8]
 [      14       1       0       0       0       0       0       0       0       0]   0.000% 	[class: 9]
 [      14       2       0       0       0       0       0       0       0       0]]  0.000% 	[class: 0]
 + average row correct: 9.9305555969477% 
 + average rowUcol correct (VOC measure): 2.7420343458652% 
 + global correct: 20.454545454545% 
==> doing epoch on training data: 
==> online epoch # 13 [batchSize = 10] 
7 
-1.5590
-1.5588
-2.6984
-2.2713
-2.4719
-3.0025
-2.5204
-2.7626
-2.9453
-2.5440
[torch.DoubleTensor of size 10]
 
-0.12320205981169 X -0.8 
-0.8 X -0.72347507306479 
-0.76395861384964 X -0.8 
-0.8 X -0.26742063267202 
-0.8 X -0.8 

==> time to learn 1 sample = 7.1828244253993ms 
ConfusionMatrix:
[[      39      75       0       0       0       0       0       0       0       0]   34.211% 	[class: 1]
 [      60      69       0       0       0       0       0       0       0       0]   53.488% 	[class: 2]
 [      13      19       0       0       0       0       0       0       0       0]   0.000% 	[class: 3]
 [      18      35       0       0       0       0       0       0       0       0]   0.000% 	[class: 4]
 [      14      24       0       0       0       0       0       0       0       0]   0.000% 	[class: 5]
 [      11      11       0       0       0       0       0       0       0       0]   0.000% 	[class: 6]
 [      17      21       0       0       0       0       0       0       0       0]   0.000% 	[class: 7]
 [      14      13       0       0       0       0       0       0       0       0]   0.000% 	[class: 8]
 [       5      17       0       0       0       0       0       0       0       0]   0.000% 	[class: 9]
 [      15      22       0       0       0       0       0       0       0       0]]  0.000% 	[class: 0]
 + average row correct: 8.7698900699615% 
 + average rowUcol correct (VOC measure): 3.2731463015079% 
 + global correct: 21.09375% 
==> testing on test set: 
9 
-1.5180
-1.4910
-2.7505
-2.2810
-2.4999
-3.0537
-2.5557
-2.8277
-3.0332
-2.5850
[torch.DoubleTensor of size 10]
 
-0.8 X -0.64584203580931 
-0.8 X -0.64584203580931 
-0.8 X -0.64584203580931 
-0.8 X -0.64584203580931 
-0.8 X -0.64584203580931 

==> time to test 1 sample = 2.1882187236439ms 
ConfusionMatrix:
[[       3      42       0       0       0       0       0       0       0       0]   6.667% 	[class: 1]
 [       0      48       0       0       0       0       0       0       0       0]   100.000% 	[class: 2]
 [       0      15       0       0       0       0       0       0       0       0]   0.000% 	[class: 3]
 [       0      27       0       0       0       0       0       0       0       0]   0.000% 	[class: 4]
 [       0      19       0       0       0       0       0       0       0       0]   0.000% 	[class: 5]
 [       0       7       0       0       0       0       0       0       0       0]   0.000% 	[class: 6]
 [       0      16       0       0       0       0       0       0       0       0]   0.000% 	[class: 7]
 [       0      12       0       0       0       0       0       0       0       0]   0.000% 	[class: 8]
 [       0      15       0       0       0       0       0       0       0       0]   0.000% 	[class: 9]
 [       0      16       0       0       0       0       0       0       0       0]]  0.000% 	[class: 0]
 + average row correct: 10.666666701436% 
 + average rowUcol correct (VOC measure): 2.8786482661963% 
 + global correct: 23.181818181818% 
==> doing epoch on training data: 
==> online epoch # 14 [batchSize = 10] 
7 
-1.6542
-1.4801
-2.6812
-2.3329
-2.5139
-2.9868
-2.5193
-2.7914
-2.9986
-2.3801
[torch.DoubleTensor of size 10]
 
-0.8 X 0.25590383814655 
-0.77406641627686 X -0.09940532480746 
-0.8 X -0.8 
-0.33485479894691 X 0.0052957503457085 
0.30295605570862 X -0.61561950900376 

==> time to learn 1 sample = 7.2680078446865ms 
ConfusionMatrix:
[[      47      67       0       0       0       0       0       0       0       0]   41.228% 	[class: 1]
 [      50      79       0       0       0       0       0       0       0       0]   61.240% 	[class: 2]
 [      18      14       0       0       0       0       0       0       0       0]   0.000% 	[class: 3]
 [      22      31       0       0       0       0       0       0       0       0]   0.000% 	[class: 4]
 [      14      24       0       0       0       0       0       0       0       0]   0.000% 	[class: 5]
 [      12      10       0       0       0       0       0       0       0       0]   0.000% 	[class: 6]
 [      20      18       0       0       0       0       0       0       0       0]   0.000% 	[class: 7]
 [       7      20       0       0       0       0       0       0       0       0]   0.000% 	[class: 8]
 [      10      12       0       0       0       0       0       0       0       0]   0.000% 	[class: 9]
 [      12      25       0       0       0       0       0       0       0       0]]  0.000% 	[class: 0]
 + average row correct: 10.246838033199% 
 + average rowUcol correct (VOC measure): 3.9417305588722% 
 + global correct: 24.609375% 
==> testing on test set: 
9 
-1.5975
-1.3854
-2.6581
-2.2939
-2.5371
-2.9779
-2.6454
-2.8625
-3.0541
-2.6431
[torch.DoubleTensor of size 10]
 
-0.8 X -0.8 
-0.8 X -0.8 
-0.8 X -0.8 
-0.8 X -0.8 
-0.8 X -0.8 

==> time to test 1 sample = 3.0777497725053ms 
ConfusionMatrix:
[[       0      45       0       0       0       0       0       0       0       0]   0.000% 	[class: 1]
 [       0      48       0       0       0       0       0       0       0       0]   100.000% 	[class: 2]
 [       0      15       0       0       0       0       0       0       0       0]   0.000% 	[class: 3]
 [       0      27       0       0       0       0       0       0       0       0]   0.000% 	[class: 4]
 [       0      19       0       0       0       0       0       0       0       0]   0.000% 	[class: 5]
 [       0       7       0       0       0       0       0       0       0       0]   0.000% 	[class: 6]
 [       0      16       0       0       0       0       0       0       0       0]   0.000% 	[class: 7]
 [       0      12       0       0       0       0       0       0       0       0]   0.000% 	[class: 8]
 [       0      15       0       0       0       0       0       0       0       0]   0.000% 	[class: 9]
 [       0      16       0       0       0       0       0       0       0       0]]  0.000% 	[class: 0]
 + average row correct: 10% 
 + average rowUcol correct (VOC measure): 2.1818181872368% 
 + global correct: 21.818181818182% 
==> doing epoch on training data: 
==> online epoch # 15 [batchSize = 10] 
